<!doctype html>
<head>
<meta name="google-site-verification" content="txmqQrMWeC-Q8aYQOBrl04hiVU-3jBbfBsj5vK3OWSE" />
<meta charset="utf-8">
<link rel="stylesheet" href="../static/style.css">
<title>Blog — Jürgen Gmach</title>
</head>
<body>
  <header>
    <h1>Jürgen Gmach</h1>
    <nav>
      <ul class="nav navbar-nav">
        <li><a href="../">About me</a></li>
        
          <li class="active"><a href="../blog/">Blog</a></li>
        
      </ul>
    </nav>
  </header>
  <div class="page">
    
  
    
  <div class="blog-post">
  
    <h1><a href="../blog/bite-my-shiny-type-annotated-library/">Bite my shiny, type-annotated library!</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/jugmac00">Jürgen Gmach</a>
    
    on 2021-05-09
  </p>
  <p>How do you make type annotations available to the users of your library?</p>
<p>Well, you just type annotate your library, right?</p>
<p>No!</p>
<p>But let's step back for a moment.</p>
<h2>Flask 2.0 goes full type annotations</h2>
<p>This morning I read David Lord's <a href="https://twitter.com/davidism/status/1391130343286001664">announcement</a> that Flask, Jinja, Click, Werkzeug, MarkupSafe,
and ItsDangerous are now fully type annotated,
and new releases will be available next week.</p>
<p>Ok, as I typed <a href="https://github.com/jugmac00/flask-reuploaded">Flask-Reuploaded</a> almost a year ago,
I certainly noticed that Flask was not typed back then,
but external type information was provided via <a href="https://github.com/python/typeshed">typeshed</a>,
which I remember lively, as I had to add a missing type annotation for <a href="https://github.com/python/typeshed/pull/4308">Werkzeug</a>.</p>
<h2>I wonder how...</h2>
<p>I immediately wondered, how the type checkers then would know whether to use the inline type information or the type stubs from <strong>typeshed</strong>.</p>
<p>Anthony Sottile responded on the Twitter thread,
that <a href="https://www.python.org/dev/peps/pep-0561/">PEP 561</a> handles this and he linked to one of his <a href="https://www.youtube.com/watch?v=n4GJ8rp6DpE">videos</a>.</p>
<p>In short - you need to include an empty <code>py.typed</code> in your repository/package.</p>
<p>What?</p>
<p>So, this basically means the applied type annotations have been in vain - for almost an entire year.</p>
<p>I am not the only one bitten by that. I am in <a href="https://github.com/encode/httpx/issues/193">very good company</a>.</p>
<p>By the way... <code>py.typed</code> has to be in your package root, not necessarily in your git root!</p>
<h2>Make mypy and co aware of your type annotations</h2>
<p>So, we know what to do, but how?</p>
<p>This depends on your build backend... and some more things,
like whether you prefer <code>setup.py</code> or <code>setup.cfg</code>,
whether you prefer to use <code>package_data</code> or rather <code>include_package_data</code> and use a <code>MANIFEST.in</code>...</p>
<p>Nobody claimed Python packaging is easy!</p>
<h3>MANIFEST.in</h3>
<p>After adding <code>py.typed</code> to my repository,
the indispensible <a href="https://pypi.org/project/check-manifest/">check-manifest</a> told me what to do:</p>
<pre><code>❯ check-manifest 
lists of files in version control and sdist do not match!
missing from sdist:
  py.typed
suggested MANIFEST.in rules:
  include *.typed
</code></pre>
<p>or simply add e.g. ...</p>
<pre><code>include src/your_package/py.typed
</code></pre>
<p>P.S.: Do not forget to add the <code>include_package_data=True</code> directive to your <code>setup.py</code>,
otherwise <code>py.typed</code> will be included in the sdist, but not in the wheel.</p>
<p>Sounds logical? Right... :-/</p>
<h3>setup.py</h3>
<p>If you do not use a <code>MANIFEST.in</code>, but <code>setuptools</code> with a <code>setup.py</code>...</p>
<pre><code>setup(
    package_data={"your_package": ["py.typed"]},
)
</code></pre>
<p>While we are at it... take care that <code>py.typed</code> is not matched by <code>exclude_package_data</code>.</p>
<p>Got it? Almost :-)</p>
<p>You also need to make sure you have the <code>zip_safe=False</code> directive set.</p>
<h3>setup.cfg</h3>
<p>If you prefer a <code>setup.cfg</code> over a <code>setup.py</code>...</p>
<pre><code>[options.package_data]
your_package = py.typed
</code></pre>
<h3>poetry</h3>
<p>If you are into <code>poetry</code>...</p>
<pre><code>[tool.poetry]
packages = [
  {include = "your_package/py.typed"},
]
</code></pre>
<h3>flit</h3>
<p>No clue. Do you know? Drop me a line via email or twitter,
contact details see <a href="https://jugmac00.github.io">https://jugmac00.github.io</a></p>
<h2>Conclusion</h2>
<p>I want to end this journey into the depths of Python packaging with the famous words of a colleague on mine:</p>
<p>"Kaum macht man's richtig, schon geht's."</p>
<p>(Translation: When you start doing it the right way, it will eventually work out.)</p>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/testing-the-tox-4-pre-release-at-scale/">Testing the tox 4 pre-release at scale</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/jugmac00">Jürgen Gmach</a>
    
    on 2021-03-01
  </p>
  <p>Every once in a while,
you may read that one of your favorite used packages announces a new version.</p>
<p>Sometimes even a so-called alpha version is announced.</p>
<p>The maintainers then politely ask you, the user, to test the package,
and give feedback if anything is broken.</p>
<p>When the upcoming <a href="https://docs.pytest.org/en/stable/">pytest</a> version 6 had been announced,
I wrote a short instruction on how to
<a href="https://github.com/jugmac00/til/blob/master/python/install-release-candidates.md">install pre-releases</a>.</p>
<p>This time, <a href="https://tox.readthedocs.io/en/latest/">tox</a>,
the <strong>virtualenv</strong> management and test tool,
announced a new version 4, but it is not just a new version,
it is a complete rewrite by <a href="https://twitter.com/gjbernat">Bernát Gábor</a>!</p>
<p>So, if you use <strong>tox</strong>, and you certainly should,
testing your package with <strong>tox 4 alpha</strong> is highly recommended.</p>
<p>Stop reading now, and try it - I am serious!</p>
<p>I did test an early alpha version,
and found quite a couple of issues for the projects I maintain (
<a href="https://github.com/tox-dev/tox/issues/1781">1</a>
<a href="https://github.com/tox-dev/tox/issues/1782">2</a>
<a href="https://github.com/tox-dev/tox/issues/1783">3</a>
<a href="https://github.com/tox-dev/tox/issues/1804">4</a>
<a href="https://github.com/tox-dev/tox/issues/1859">5</a>
<a href="https://github.com/tox-dev/tox/issues/1868">6</a>
).</p>
<p>They were all addressed in no time.</p>
<p>Reporting issues in pre-releases is important both for you,
so you can use the new version once it gets released without any hassle,
and also for the maintainer,
who does not get stressed out completely on the day the new package gets released.</p>
<p>End of story...</p>
<p>Not yet!</p>
<h2>alpha testing on scale</h2>
<p>Maybe you know that I am contributor to the <a href="https://zope.readthedocs.io/en/latest/">Zope project</a>.
Zope is the bedrock of Python web frameworks.
And while development has come to a <em>sustainable</em> path, it is still used out in the wild.</p>
<p>One characteristic, which I miss in other projects, is
that not only the core project,
but also hundreds and hundreds of plugins are managed together in one <a href="https://github.com/zopefoundation">GitHub organization</a>.</p>
<p>I mentioned the advantages already a couple of times.</p>
<p>All contributors can access all packages, fix minor issues,
which means no package is left behind,
and no package depends on the good will of a single maintainer,
who always starts euphoric,
and at one point in time neglects the project because of real life or switching company or language.</p>
<p>Ok, so we use <strong>tox</strong> in most of the roundabout 300 active packages.</p>
<p>How would I be able to run <strong>tox alpha</strong> on all of them?</p>
<h2>all-repos to the rescue</h2>
<p>I already wrote about <a href="https://github.com/asottile/all-repos">all-repos</a>
by <a href="https://twitter.com/codewithanthony">Anthony Sottile</a> previously in
<a href="https://jugmac00.github.io/blog/how-to-create-hundreds-of-pull-requests-with-a-single-command/">How to create hundreds of pull requests with a single command?</a>,
but this time it is different.</p>
<p>If you have not encountered <strong>all-repos</strong> yet...</p>
<p>In short, with <strong>all-repos</strong> you can clone all of your and your organization's repositories,
find files,
grep in them,
mass apply changes to them and finally create pull requests,
all from the command line.</p>
<p>But afaik <strong>all-repos</strong> does not offer an easy way to run a custom command on all repositories.</p>
<p>Also, unlike e.g. <strong>pytest</strong>, it also does not offer any plugin mechanism, but ...</p>
<p>It is super easy to use <strong>all-repos</strong> as a library.</p>
<h2>use the source</h2>
<p>While the <a href="https://github.com/asottile/all-repos/blob/master/README.md">README</a> offers a nice overview of the API,
I directly dug into the source code to find some inspiration on how to write my custom <strong>all-repos</strong> command line script.</p>
<p><strong>all-repos</strong> offers a couple of command line entry points
and also a couple of <a href="https://github.com/asottile/all-repos/tree/master/all_repos/autofix">example usages</a>,
and after looking around a bit,
I chose the script for <a href="https://github.com/asottile/all-repos/blob/master/all_repos/list_repos.py">all-repos-list-repos</a> as a template,
which basically does everything I wanted,
except executing <strong>tox</strong>.</p>
<p>So, <strong>all-repos</strong> exposes a <code>load_config</code> method,
with which I get hold of all repositories,
and instead of just printing their paths as in <code>all-repos-list-repos</code>,
I need to check whether they contain a <strong>tox.ini</strong> file,
and if so, run <strong>tox4 alpha</strong>.</p>
<p>After that I check the return code of <strong>tox</strong>.
If the run succeeds, and it does for <strong>tox3</strong> otherwise our CI would not be green,
all is ok, otherwise I need to collect the repo name for later inspection.</p>
<p>At the end I just print the result.</p>
<h3>first version of the script</h3>
<pre><code class="lang-python">def main(argv: Optional[Sequence[str]] = None) -&gt; int:
    parser = argparse.ArgumentParser(
        description=&#39;Run tox4 on all cloned repositories.&#39;,
        usage=&#39;python main.py -C configfile&#39;,
    )
    cli.add_common_args(parser)
    cli.add_output_paths_arg(parser)
    args = parser.parse_args(argv)

    config = load_config(args.config_filename)
    results = {&quot;notox&quot;: [],
               &quot;successful&quot;: [],
               &quot;problems&quot;: [],
    }
    for i, repo in enumerate(config.get_cloned_repos()):
        path_repo = os.path.join(config.output_dir, repo)
        path_tox = os.path.join(path_repo, &quot;tox.ini&quot;)
        if os.path.exists(path_tox):
            print(f&quot;about to run tox for {repo}, {i+1} of {len(config.get_cloned_repos())}&quot;)
            run = subprocess.run([&quot;tox4&quot;, &quot;-e py39&quot;, &quot;-c&quot;, path_tox], capture_output=&quot;True&quot;)

            if run.returncode == 0:
                print(f&quot;tox4 run successful for {repo}&quot;)
                results[&quot;successful&quot;].append(repo)
            else:
                print(f&quot;tox4 run failed for {repo}&quot;)
                results[&quot;problems&quot;].append(repo)

        else:
            results[&quot;notox&quot;].append(repo)
            print(f&quot;{repo} does not contain a tox configuration. Boo!&quot;)
    print(results)
    return 0
</code></pre>
<p>The latest version of the script is <a href="https://github.com/jugmac00/my-all-repos">available on GitHub</a>.</p>
<p>The end...?</p>
<p>Not yet...</p>
<h2>real life issues</h2>
<p>Super easy, right?</p>
<p>Yep, except after quite some time, my Ubuntu machine got completely unresponsive.</p>
<p>Not even keyboard presses gave any reaction...</p>
<p>After a hard reset, I inspected <strong>syslog</strong>,
and found out that my machine ran out of memory and started killing processes.</p>
<p>But why?</p>
<p>I had another look at my script and still had no clue.</p>
<p>I asked at the <a href="https://discord.gg/tox">tox discord channel</a>,
and both Anthony and Bernát gave me some valuable tips on how to improve my code.</p>
<p>I ran my script again,
and after quite some time it made boom again.</p>
<p>Finally, with the help of a system monitoring tool,
I pinpointed the problem to a single repository,
which for some yet to be investigated reasons,
started an endless <strong>setuptools</strong> update circle and ate memory like crazy.</p>
<p>After I excluded this one repository,
my script finally completed,
and showed me the result.</p>
<blockquote><p>tox 4 alpha 6 on 288 Zope repositories, 17 without tox, 62 successful, 208 broken builds</p>
</blockquote>
<p>Bernát's reaction: "a 22% success here, not that great news :smile: but on plus side seems if we fix zope we should be in a decent place"</p>
<p>This was exactly my intention! :-)</p>
<p>P.S.: By the way, there are certainly not 208 different errors / bugs,
it is more like there are roundabout four different error cases,
which I will have a look at myself at first,
and when it turns out this is not a problem in the package,
I will report an issue in the issue tracker of tox.</p>
<h2>thanks</h2>
<p>Thanks to Anthony and Bernát for all your work in the Python open source eco system,
and for always being friendly and helpful!</p>
<h2>found and reported issues</h2>
<ul>
<li><a href="https://github.com/zopefoundation/zope.testrunner/issues/112"><code>package init file missing</code> warning when running tox4</a></li>
<li><a href="https://github.com/tox-dev/tox/issues/1929">tox4: fails when requirements file contains a line a la <code>-e .[test] -c constraints.xt</code></a></li>
<li><a href="https://github.com/plone/plone.memoize/issues/24">tox is broken #24</a></li>
<li><a href="https://github.com/tox-dev/tox/issues/1933">tox4: tox fails to parse tox.ini when a testenv contains <code>deps = .[test]</code></a></li>
<li><a href="https://github.com/plone/plone.app.standardtiles/issues/114">tox broken #114</a></li>
<li><a href="https://github.com/plone/plone.reload/issues/14">tox broken #14</a></li>
<li><a href="https://github.com/plone/Products.ExtendedPathIndex/issues/18">tox will break with the release of tox4 #18</a></li>
<li><a href="https://github.com/plone/diazo/issues/80">tox run broken #80</a></li>
<li><a href="https://github.com/plone/plone.app.testing/issues/74">tox broken: "ImportError: No module name <code>zope.testrunner</code> #74</a></li>
<li><a href="https://github.com/plone/plone.gallery/issues/6">tox configuration is Python 2.7 only #6</a></li>
<li><a href="https://github.com/tox-dev/tox/issues/1944">tox4: ValueError: No closing quotation (via shlex) #1944</a></li>
<li><a href="https://github.com/tox-dev/tox/issues/1945">tox4: editable installs do not work (deps) #1945</a></li>
<li><a href="https://github.com/zopefoundation/Products.PythonScripts/issues/48">tox will break when tox4 will be released #48</a></li>
<li><a href="https://github.com/tox-dev/tox/issues/1948">tox4: a possible quoting issue #1948</a></li>
<li><a href="https://github.com/zopefoundation/zopetoolkit/issues/52">tox is broken: couldn't open ...buildout.cfg #52</a></li>
<li><a href="https://github.com/zopefoundation/keas.kmi/issues/8">no support for Python 3.8 - module <code>cgi</code> has no attribute <code>escape</code> #8</a></li>
<li><a href="https://github.com/zopefoundation/bobo/issues/18">ResourceWarning: Enable tracemalloc to get the object allocation traceback</a></li>
</ul>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/convincing-an-enterprisy-app-to-work-behind-nginx-as-reverse-proxy/">Convincing an enterprisy app to work behind nginx as reverse proxy</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/@jugmac00">Jürgen Gmach</a>
    
    on 2020-10-30
  </p>
  <p>For simplicity, let's the call the app <strong>Dated HR</strong>,
a tool to "Simplify your HR work",
which offers support for time tracking, holiday, payroll...</p>
<p>So far so good, and even better,
as it is an enterprisy Windows software,
which needs to be configured with <strong>IIS</strong> and a <strong>MSSQL</strong> database,
a colleague of mine installed it on an internal Windows server.</p>
<p>The app makes a web GUI available under <a href="http://nemesis.company.local">http://nemesis.company.local</a>,
which would work like a charm - for our colleagues at site,
but not for the colleagues from the other sites.</p>
<p>But certainly, it is 2020, you want encryption via https,
and also the other colleagues need web access.</p>
<p>Setting up <strong>nginx</strong> as reverse proxy is business as usual.</p>
<p>Also, adding https via <strong>Certbot</strong> can't get much simpler:
<a href="https://certbot.eff.org/">https://certbot.eff.org/</a></p>
<p>So far, so good, the app is now available via
<a href="https://hr.company.com">https://hr.company.com</a></p>
<p>The app seems to work,
but when clicking on a special button
(I refrain from calling it a link,
as it is a humongous JavaScripty-eventlistener-from-data-attribute-fetching something),
I get a ...</p>
<p><code>This site cannot be reached" nemesis.company.local’s server IP address could not be found.</code></p>
<p>Having a look at the HTML source,
a wild mix of relative and absolute URLs show up,
where the latter have <code>http://nemesis.company.local</code> hardcoded.</p>
<p>If this was an open source app, I could</p>
<ul>
<li>read the documentation on the internet</li>
<li>have a look in the source code</li>
<li>have a look at the issue tracker</li>
<li>search on Stack Overflow</li>
<li>...</li>
</ul>
<p>...but... did I mention it is an <strong>enterprisy</strong> app?</p>
<p>So, let's tell the Windows admin to configure the app properly.</p>
<p>Turns out, there is no option.</p>
<p>Asking vendor for support also did not work out:</p>
<blockquote><p>The reported behavior cannot be changed.</p>
</blockquote>
<p>Well, maybe you cannot... but I can - possibly.</p>
<p><strong>nginx</strong>, my favorite web server,
can rewrite HTML on the fly,
via the <a href="http://nginx.org/en/docs/http/ngx_http_sub_module.html">http_sub_module</a>.</p>
<p>While this module is not compiled into <strong>nginx</strong> by default,
luckily the <strong>Ubuntu</strong> developers included it.</p>
<p>So, adding the following snippet to my location block should do the trick...</p>
<pre><code>sub_filter 'http://nemesis.company.local' 'https://$host';
sub_filter_once off;
</code></pre>
<p>where</p>
<ul>
<li>the first directive replaces the local host name with the one of the reverse proxy</li>
<li>and the second one makes sure every occurrence gets replaced</li>
</ul>
<p>After restarting <strong>nginx</strong>,
I still get the same error. <strong>bummer</strong>.</p>
<p>I double checked,
no more occurrences in the generated HTML, CSS or JavaScript...</p>
<p>Hm, let's have a look at the <strong>HTTP headers</strong> in the debug console.</p>
<p>Here we go, the <code>location</code> header of the response had the following value...</p>
<p><code>http://nemesis.company.lcoal/.../.../.../.../Default.aspx</code></p>
<p>Once more, after some googling,
the <strong>nginx</strong> documentation offered a solution
via the <a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_redirect">proxy_redirect directive</a>.</p>
<p>While <code>proxy_redirect</code> sounds a bit odd,
the description makes more sense:</p>
<blockquote><p>Sets the text that should be changed in the "Location" and "Refresh" header fields of a proxied server response.</p>
</blockquote>
<p>Very nice, let's add the following snippet to my location block...</p>
<pre><code>proxy_redirect http://nemesis.company.local https://$host;
</code></pre>
<p>After restarting <strong>nginx</strong> once more,
everything works as intended!</p>
<p>The complete location block looks like...</p>
<pre><code>location / {
    proxy_pass http://nemesis.company.local:80/;
    sub_filter 'http://nemesis.company.local' 'https://$host';
    sub_filter_once off;
    proxy_redirect http://nemesis.company.local https://$host;
    }
</code></pre>
<p>Finally, the enterprisy app works like a charm - thanks to <strong>open source</strong>!</p>
<p>P.S.: While debugging the errors,
I found several seriously outdated JS libraries with some known <strong>CVE</strong> entries.</p>
<p>Looking forward to the vendor's answer!</p>
<p>At very least the developers of this very app show good humor,
as they named the variables after cocktails,
which I can relate to.</p>
<p>Cheers! Prost! Na zdraví!</p>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/how-to-run-a-dockerized-service-via-systemd/">How to run a dockerized service via systemd?</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/@jugmac00">Jürgen Gmach</a>
    
    on 2020-10-29
  </p>
  <p>Until recently, I saw no good reason to use <strong>Docker</strong>,
as my <a href="https://batou.readthedocs.io/en/stable/">deployment tool</a> of <em>choice</em> produces approximately identical builds,
locally on my Ubuntu laptop, on staging and on production.</p>
<p>But time does not stand still and especially as I have to deploy a Java application,
it was time to rethink my strategy,
as I do not want to play the <strong>which Java runtime environment plays nicely together with which app version</strong> game.</p>
<p>Fortunately, <a href="https://www.jetbrains.com/">JetBrains</a>
offers <a href="https://hub.docker.com/r/jetbrains/youtrack/">pre-built docker images</a>
for <a href="https://www.jetbrains.com/youtrack/">YouTrack</a>, 
my favorite issue tracker,
which is the app I plan to install today.</p>
<h2>simple is not always better</h2>
<p>With a pre-built <strong>Docker</strong> image,
<a href="https://www.jetbrains.com/help/youtrack/standalone/youtrack-docker-installation.html#run-youtrack-service">running the app</a> could be as simple as ...</p>
<pre><code>docker run -it --name youtrack-server-instance  \
    -v {path to data directory}:/opt/youtrack/data \
    -v {path to conf directory}:/opt/youtrack/conf  \
    -v {path to logs directory}:/opt/youtrack/logs  \
    -v {path to backups directory}:/opt/youtrack/backups  \
    -p {port on host}:8080 \
    jetbrains/youtrack:{version}
</code></pre>
<p>... but it is both tedious to type this long command,
and also the process would not survive a reboot of the host system.</p>
<blockquote><p><strong><em>NOTE:</em></strong>
<a href="https://github.com/jugmac00/til/blob/master/docker/difference-between-docker-create-start-run.md">Do you know the difference between <code>docker create</code>, <code>docker run</code> and <code>docker start</code>?</a>.</p>
</blockquote>
<p>While we are here, let's dissect this complex command:</p>
<ul>
<li><code>run</code> creates and starts a container</li>
<li><code>-it</code> provides an interactive tty, ie show output in the terminal</li>
<li><code>--name</code> gives the container a name</li>
<li><code>-v</code> maps folders between the host and the container</li>
<li><code>-p</code> maps ports between the host and the container</li>
<li><code>jetbrains/youtrack:{version}</code> is finally the docker image</li>
</ul>
<h2>run docker container as a systemd service</h2>
<p>Instead of manually starting the docker service,
let's use <strong>systemd</strong> to start it, even after a reboot.</p>
<p>JetBrains offers a <a href="https://www.jetbrains.com/help/youtrack/standalone/run-docker-container-as-service.html">concise documentation</a> on how to do this.</p>
<h2>unit file</h2>
<p>Basically, just create a unit file at <code>/etc/systemd/system/docker.youtrack.service</code>,
with the following content...</p>
<pre><code>[Unit]
Description=YouTrack Service
After=docker.service
Requires=docker.service

[Service]
TimeoutStartSec=0
Restart=always
ExecStartPre=-/usr/bin/docker exec %n stop
ExecStartPre=-/usr/bin/docker rm %n
ExecStartPre=/usr/bin/docker pull jetbrains/youtrack:&lt;version&gt;
ExecStart=/usr/bin/docker run --rm --name %n \
    -v &lt;path to data directory&gt;:/opt/youtrack/data \
    -v &lt;path to conf directory&gt;:/opt/youtrack/conf \
    -v &lt;path to logs directory&gt;:/opt/youtrack/logs \
    -v &lt;path to backups directory&gt;:/opt/youtrack/backups \
    -p &lt;port on host&gt;:8080 \
    jetbrains/youtrack:&lt;version&gt;

[Install]
WantedBy=default.target
</code></pre>
<p>... where, on a very high level,</p>
<ul>
<li>the unit section gives this service a name, and defines the prerequisites and dependencies,</li>
<li>the service section configures the command to be executed,</li>
<li>and the install section defines when this service should be started.</li>
</ul>
<p>Finally, you can enable it via <code>systemctl enable docker.youtrack</code>,
so it starts after the next reboot,
and start and stop it manually via <code>sudo service docker.youtrack start</code> / <code>sudo service docker.youtrack stop</code>.</p>
<h2>some failures</h2>
<p>This all worked out perfectly,
and <code>YouTrack</code> was available via my browser,
except I was worried a bit about the output of <code>systemctl status docker.youtrack</code>...</p>
<p><img src="../blog/how-to-run-a-dockerized-service-via-systemd/status.png" alt="systemd status"></p>
<p>Why are there two failures?</p>
<p>From all I knew about <strong>Docker</strong>,
the run command should create and start a container,
so the container should be persistent,
even after a restart.</p>
<p>Which would finally mean,
<strong>systemd</strong> should successfully stop and delete the docker container e.g. on restart.</p>
<h3>dissect the service section of the unit file</h3>
<p>Let's have another look at the <em>Service</em> section from above, especially at the following two lines.</p>
<pre><code>ExecStartPre=-/usr/bin/docker exec %n stop
ExecStartPre=-/usr/bin/docker rm %n
</code></pre>
<ul>
<li><code>ExecStartPre</code> is pretty self explaining, and means "execute this command before starting the service"</li>
<li>the dash, <code>-</code>, just before the command, means it is ok when the following command fails = do not stop on failure!</li>
<li><code>%n</code> expands to the service, ie <code>docker.youtrack.service</code></li>
</ul>
<p>So, this means, <strong>failures</strong> are expected!</p>
<p>Let's have a look at the <code>run</code> command...</p>
<p><code>ExecStart=/usr/bin/docker run --rm --name %n</code></p>
<ul>
<li><code>ExecStart</code> is the main process</li>
<li><code>docker run</code>, as we now know, creates and starts a container</li>
<li><code>--rm</code> - here we go, this makes sure the container is deleted on exit!</li>
<li><code>--name</code> sets the name of the container</li>
<li><code>%n</code> is the placeholder for the service</li>
</ul>
<h2>conclusion</h2>
<p>Everything is working as expected!</p>
<p>The <code>stop</code> and the <code>delete</code> commands are only safe guards,
just in case another container with the same name exists,
or is even running.</p>
<p>Running pre-built <strong>Docker</strong> images is a breeze.</p>
<p>But you certainly should know the basics :-)</p>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/how-to-create-hundreds-of-pull-requests-with-a-single-command/">How to create hundreds of pull requests with a single command?</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/@jugmac00">Jürgen Gmach</a>
    
    on 2020-10-28
  </p>
  <p>... or "How to win <strong>#hacktoberfest</strong>"?</p>
<p>Seriously...</p>
<ul>
<li><strong>#hacktoberfest</strong> is no longer cool ( <a href="https://blog.domenic.me/hacktoberfest/">Hacktoberfest is Hurting Open Source</a> )</li>
<li>you cannot win it anyway</li>
<li>the mass pull requests I created (see below) went all to repositories, which do not take part at <strong>#hacktoberfest</strong></li>
</ul>
<hr>
<blockquote><p><strong><em>NOTE:</em></strong>
If you are not interested in the story behind,
I also created a <a href="https://github.com/jugmac00/til/blob/master/zope/how-to-update-all-zopefoundation-repositories-at-once.md">concise "today-I-learned" post</a>.</p>
</blockquote>
<hr>
<h2>prologue</h2>
<p>The company I work for has been using <a href="https://github.com/zopefoundation/Zope/">Zope</a>,
the granddaddy of Python web application servers,
for more than 15 years.</p>
<p>What I love most about <strong>Zope</strong>,
except for the stability and the low record of <a href="https://www.cvedetails.com/vulnerability-list/vendor_id-370/Zope.html">security issues</a>,
is the small but fine community.</p>
<p>Especially I love the fact, that almost all <strong>Zope</strong> plugins,
which are sometimes called <strong>Products</strong>,
are united in the <a href="https://github.com/zopefoundation"><code>zopefoundation</code></a> GitHub organization,
with a current count of 392, of which 330 are active.</p>
<p>Combine the idea of a central repository with the ease of anybody to <a href="https://www.zope.org/developer/becoming-a-committer.html">contribute</a>,
and you'll see the obvious benefits immediately:</p>
<p>Do you rely on one package, and there was a breaking change in a dependency?
Do you need support for the newest Python version?
No problem, either ask somebody for help or fix it yourself.
No single repository will be left behind.</p>
<p>Compare this to other frameworks,
where most of the plugins are maintained by single persons,
which start extremely enthusiastic and at some point in time loose interest.</p>
<p>Having to maintain hundreds of repositories certainly comes with a cost.</p>
<p>It is especially tedious,
when you have to do small changes to lots or even all repositories.</p>
<h2>the initial situation</h2>
<p>We, the Zope maintainers/contributors,
need to test our plugins against Python <code>3.9</code>,
but <a href="https://travis-ci.com/">Travis</a>,
the CI system we use,
only offered Python <code>3.9-dev</code>, but no final version.</p>
<p>So we tested against <code>3.9-dev</code>.</p>
<h2>the "problem"</h2>
<p>Travis finally provides <a href="https://travis-ci.community/t/python-3-9-0-build/10091/13?u=jugmac00">Python 3.9 final</a>.</p>
<p>But how would we <a href="https://github.com/zopefoundation/meta/issues/37">update all repositories</a> which still use Python <code>3.9-dev</code>?</p>
<p><a href="https://github.com/zopefoundation/meta/issues/37#issuecomment-717751883">Manually?</a> No way!</p>
<h2>the solution</h2>
<p><a href="https://github.com/asottile/all-repos">all-repos</a> provides a set of CLI tools,
which enables you to e.g. clone all repos of a GitHub organization,
search in them,
do mass updates to them,
and even finally create pull requests.</p>
<p><code>all-repos</code> was created by one of the many Anthony Sottile clones out there,
without them, the Python world would not be the same
(Think of <code>pre-commit</code>, <code>pyupgrade</code>, <code>tox</code>, <code>flake8</code>, ...).</p>
<p>Before you can start to work with <code>all-repos</code>,
you need to</p>
<ul>
<li>install <a href="https://pypi.org/project/all-repos/">all-repos</a></li>
<li><a href="https://github.com/settings/tokens/new">create a GitHub API token</a></li>
<li>create a configuration file</li>
</ul>
<p>I assume you are able to install a Python package, either via <code>pipx</code>, in a virtual environment, or ...</p>
<p>Also, the token creation is straight forward.
A token basically allows programs to interact with GitHub on your behalf.</p>
<h3>configuration</h3>
<p>The configuration is done with a JSON file, which is named <code>all-repos.json</code> by default.</p>
<p>Mine looks like so</p>
<pre><code>{
    "output_dir": "output",
    "source": "all_repos.source.github_org",
    "source_settings":  {
        "api_key": "xxx",
        "org": "zopefoundation"
    },
    "push": "all_repos.push.github_pull_request",
    "push_settings": {
        "api_key": "xxx",
        "username": "jugmac00"
    }
}
</code></pre>
<p>where</p>
<ul>
<li><code>output_dir</code> is the folder where the repositories are cloned into</li>
<li><code>source</code> is the way how to get hold of the repositories, in our case it is a GitHub organization</li>
<li><code>api_key</code> is needed in order to access / write to the repositories</li>
<li><code>org</code> is the corresponding GitHub organization</li>
<li><code>push</code> configures what should be done after changes had been applied, here it is "create a pull request on GitHub"</li>
<li><code>username</code> is the username which should be used for the pull request</li>
</ul>
<p>Once this is done, we are ready to go.</p>
<h3>cloning all repositories</h3>
<p>The most basic task is to clone all repositories. Too easy? Think of Zope`s 300+ repositories.</p>
<pre><code>❯ all-repos-clone
Initializing zopefoundation/zope.dottedname
Initialized empty Git repository in /tmp/Zope/output/zopefoundation/zope.dottedname/.git/
Initializing zopefoundation/zc.relationship
Initialized empty Git repository in /tmp/Zope/output/zopefoundation/zc.relationship/.git/
Initializing zopefoundation/zope.app.dependable
...
</code></pre>
<h3>grepping all repos</h3>
<p>Already one and a half year ago, I evaluated <code>all-repos</code>, but struggled a bit to wrap my head around advanced concepts like the so-called <code>autofixers</code>.</p>
<p>On the other hand, grepping was and is straight forward, e.g. the following command looks for <code>3.9-dev</code> in all repositories' <code>.travis.yml</code> file.</p>
<pre><code>❯ all-repos-grep --repos-with-matches 3.9-dev -- '.travis.yml'
output/zopefoundation/AccessControl
output/zopefoundation/Acquisition
output/zopefoundation/AuthEncoding
output/zopefoundation/DocumentTemplate
...
</code></pre>
<p>where</p>
<ul>
<li><code>all-repos-grep</code> is the CLI tool we use =&gt; grep on all repositories</li>
<li><code>--repos-with-matches</code> =&gt; only show repositories with a match</li>
<li><code>3.9-dev</code> =&gt; the string we are looking for</li>
<li><code>.travis.yml</code> =&gt; only look in files named <code>.travis.yml</code></li>
</ul>
<p>This is all fun, but how to get this party started?</p>
<h3>update all <code>.travis.yml</code> files</h3>
<blockquote><p><strong><em>NOTE:</em></strong>
When you are on <strong>macOS</strong>, please have a look at the <a href="https://github.com/asottile/all-repos#all-repos-sed-options-expression-filenames">documentation</a> as the following command uses <strong>GNU sed</strong>,
which may not be present on macOS.</p>
</blockquote>
<p>While <code>all-repos-grep</code> and other CLI commands like <code>all-repos-find-files</code> are read-only,
the real fun starts with so-called <code>autofixers</code>.</p>
<p>Basically, an <code>autofixer</code> applies changes to all repositories which match a certain pattern.</p>
<p>While there are pre-built <code>autofixers</code> like <code>all-repos-sed</code>,
which we will use in a minute,
you can also <a href="https://github.com/asottile/all-repos#writing-an-autofixer">create autofixers yourself</a>.</p>
<p>Ok, so we can bulk-modify repositories, but what then?
How do I commit the changes?
How do I create a branch?
A pull request?</p>
<p>Ok, first things first, let's try to update all repositories...</p>
<p><code>all-repos-sed --commit-msg "Use Python 3.9 final" s/3.9-dev/3.9/g -- '.travis.yml'</code></p>
<p>where</p>
<ul>
<li><code>all-repos-sed</code> is the CLI command we use =&gt; use <a href="https://www.gnu.org/software/sed/manual/sed.html">sed</a> on all repositories</li>
<li><code>--commit-msg "Use Python 3.9 final"</code> =&gt; use a custom commit message</li>
<li><code>s/3.9-dev/3.9/g</code> =&gt; replace <code>3.9-dev</code> with <code>3.9</code></li>
<li><code>.travis.yml</code> =&gt; only look in <code>.travis.yml</code> files</li>
</ul>
<p>Still, what about the branches, the commits and the pull request...? Never mind, let's give it a go...</p>
<pre><code>/tmp/Zope 
❯ all-repos-sed --commit-msg "Use Python 3.9 final" s/3.9-dev/3.9/g -- '.travis.yml'
***output/zopefoundation/Products.PythonScripts
$ git clone --quiet output/zopefoundation/Products.PythonScripts /tmp/tmp_ve9eest
$ git remote set-url origin git@github.com:zopefoundation/Products.PythonScripts
$ git fetch --prune --quiet
$ git checkout --quiet origin/HEAD -b all-repos_autofix_all-repos-sed
$ sed -i s/3.9-dev/3.9/g .travis.yml
$ git diff origin/HEAD --exit-code
***output/zopefoundation/ZODB
$ git clone --quiet output/zopefoundation/ZODB /tmp/tmp56hy_wls
$ git remote set-url origin git@github.com:zopefoundation/ZODB
$ git fetch --prune --quiet
$ git checkout --quiet origin/HEAD -b all-repos_autofix_all-repos-sed
$ sed -i s/3.9-dev/3.9/g .travis.yml
$ git diff origin/HEAD --exit-code
***output/zopefoundation/transaction
$ git clone --quiet output/zopefoundation/transaction /tmp/tmpt5z_p_jc
$ git remote set-url origin git@github.com:zopefoundation/transaction
$ git fetch --prune --quiet
$ git checkout --quiet origin/HEAD -b all-repos_autofix_all-repos-sed
$ sed -i s/3.9-dev/3.9/g .travis.yml
$ git diff origin/HEAD --exit-code
***output/zopefoundation/BTrees
$ git clone --quiet output/zopefoundation/BTrees /tmp/tmpgw8mhej5
$ git remote set-url origin git@github.com:zopefoundation/BTrees
$ git fetch --prune --quiet
$ git checkout --quiet origin/HEAD -b all-repos_autofix_all-repos-sed
$ sed -i s/3.9-dev/3.9/g .travis.yml
$ git diff origin/HEAD --exit-code
***output/zopefoundation/persistent
$ git clone --quiet output/zopefoundation/persistent /tmp/tmpk7vmtr0w
$ git remote set-url origin git@github.com:zopefoundation/persistent
$ git fetch --prune --quiet
$ git checkout --quiet origin/HEAD -b all-repos_autofix_all-repos-sed
$ sed -i s/3.9-dev/3.9/g .travis.yml
$ git diff origin/HEAD --exit-code
diff --git a/.travis.yml b/.travis.yml
index dba5aa4..dda3ec5 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -17,7 +17,7 @@ python:
   - 3.6
   - 3.7
   - 3.8
-  - 3.9-dev
+  - 3.9

 jobs:
   include:
$ git commit --quiet -a -m 'Use Python 3.9 final

Committed via https://github.com/asottile/all-repos'
$ git push origin HEAD:all-repos_autofix_all-repos-sed --quiet
remote: 
remote: Create a pull request for 'all-repos_autofix_all-repos-sed' on GitHub by visiting:
remote:      https://github.com/zopefoundation/persistent/pull/new/all-repos_autofix_all-repos-sed
remote: 
Pull request created at https://github.com/zopefoundation/persistent/pull/152
...
</code></pre>
<p>Holy moly! It's a thing!</p>
<p>One after another,
this awesome tool goes through all repositories,
creates a branch,
updates <code>.travis.yml</code>,
commits the changes,
and creates a pull request,
all automagically!</p>
<p>Yeah, I know, that is what it is supposed to do, but holy sh... it's real!</p>
<h3>meanwhile on Travis</h3>
<p><img src="../blog/how-to-create-hundreds-of-pull-requests-with-a-single-command/travis.png" alt="Travis"></p>
<h3>meanwhile on GitHub</h3>
<p><img src="../blog/how-to-create-hundreds-of-pull-requests-with-a-single-command/github.png" alt="Pull-Request-Mania-at-GitHub"></p>
<p>Poor co-maintainers, who need to review all those pull requests!</p>
<p>One already asked,
whether it is possible to directly push to master...
<a href="https://github.com/asottile/all-repos#all_repospushmerge_to_master">yes, it is</a>!</p>
<h3>after one hour in my inbox</h3>
<p><img src="../blog/how-to-create-hundreds-of-pull-requests-with-a-single-command/inbox.png" alt="email-flood"></p>
<h2>conclusion</h2>
<p>This amazing tool works like a charm!
For this task, it saved me at least a couple of hours.</p>
<p>And there is much more it can do!</p>
<h2>thanks</h2>
<p>Thanks a lot, Anthony!
<code>all-repos</code> certainly is another invaluable asset for working as a professional software developer,
and it especially helps maintaining <strong>open source</strong> projects on a large scale.</p>
<h2>further information</h2>
<ul>
<li><a href="https://github.com/jugmac00/til/blob/master/zope/how-to-update-all-zopefoundation-repositories-at-once.md">concise version of this blog post</a></li>
<li><a href="https://pypi.org/project/all-repos/">all-repos</a> on PyPI</li>
<li><a href="https://twitter.com/codewithanthony">Anthony on Twitter</a></li>
</ul>
<h2>updates</h2>
<p>2020-10-28</p>
<ul>
<li>add info on how to <a href="https://github.com/asottile/all-repos#all_repospushmerge_to_master">directly push to master</a></li>
</ul>
<p>2020-03-11</p>
<ul>
<li>remove criticism of the documentation, <a href="https://github.com/asottile/all-repos/issues/140">constructive attempts to fix it is better</a>, right?</li>
<li>add default name of configuration file</li>
</ul>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/flask-reuploaded/">Flask-Reuploaded</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/@jugmac00">Jürgen Gmach</a>
    
    on 2020-06-28
  </p>
  <p>It all started with this error message:</p>
<pre><code> File "/Projects/xxx/venv/lib/python3.7/site-packages/flask_uploads.py", line 26, in &lt;module&gt;
from werkzeug import secure_filename, FileStorage
ImportError: cannot import name 'secure_filename' from 'werkzeug''
</code></pre>
<p>Trying to build my <code>Flask</code> application, the above error message was generated,
as <code>Werkzeug</code>, a very important library in the <code>Flask</code> ecosystem,
changed its API in version 1.0, back in February 2020.</p>
<p>This broke a lot of plugins.</p>
<p><img src="../blog/flask-reuploaded/twitter-ronacher.png" alt="Alt-Text"></p>
<p><a href="https://twitter.com/mitsuhiko/status/1225758711009902592">Twitter thread</a></p>
<p>As my app relies on <code>Flask-Uploads</code>, I had a look at the problem
and finally provided a <a href="https://github.com/maxcountryman/flask-uploads/pull/28">pull request</a>
to the <code>Flask-Uploads</code> repository on GitHub.</p>
<p>This pull request was merged, but the maintainer deliberately chose not to release a new version to PyPi,
though I even offered my help.</p>
<p>You can read his final argument here
<a href="https://github.com/maxcountryman/flask-uploads/issues/29#issuecomment-614218327">https://github.com/maxcountryman/flask-uploads/issues/29#issuecomment-614218327</a></p>
<p>The latest version on PyPi (0.2.1) is from 2016,
and that one does not work with a current Flask/Werkzeug version.</p>
<p>You certainly could pin <code>Flask-Uploads</code> to a GitHub commit ID.</p>
<p>I think this is inconvenient at least, and doing so caused me a lot of problems,
as pinning a GitHub commit ID worked on my dev machine, but Travis CI was broken.
For reasons.</p>
<p>While I finally managed it <a href="https://user-images.githubusercontent.com/9895620/74611968-21140a00-5101-11ea-9280-4102f384b9a1.png">somehow</a>,
I felt a bit sad for all those developers asking for help and a new release.</p>
<p>Fast forward six months, there is still no new release.</p>
<p>I have thought about this situation a lot.
On the one hand, the GitHub repository is kinda up to date (the test suite is broken, and some more... ),
on the other hand there are many developers out there having trouble to fix their broken app.</p>
<p>So, yesterday I finally decided to fork this package,
and after fixing the test suite and some more housekeeping,
I released a new version to PyPi,
most importantly with a fix to the broken <code>Werkzeug</code> import - and tons more.</p>
<p>As only the original maintainer has access to <code>Flask-Uploads</code> on PyPi,
I had to create a new name:</p>
<p><a href="https://pypi.org/project/Flask-Reuploaded/"><code>Flask-Reuploaded</code></a>.</p>
<p>One of my main goals is to stay compatible with <code>Flask-Uploads</code>.
It even is a drop-in replacement!</p>
<p>This means, instead of installing <code>Flask-Uploads</code>,
you only have to install <code>Flask-Reuploaded</code> and your migration work is finished.
You do not have to change a single line of code.</p>
<p>The package is found here
<a href="https://pypi.org/project/Flask-Reuploaded/">https://pypi.org/project/Flask-Reuploaded/</a></p>
<p>And the repository is here
<a href="https://github.com/jugmac00/flask-reuploaded">https://github.com/jugmac00/flask-reuploaded</a></p>
<p>Speaking of repository, while I have fixed the broken test suite,
set up CI and more, there is still lots to do - especially beginner friendly tasks.
If you ever wanted to contribute to open source, why not to the library you use?
There are many <a href="https://github.com/jugmac00/flask-reuploaded/issues">open issues</a>.</p>
<p>When you now think... huh, this one guy... why should I use his package?
Maybe he is too busy soon, too?</p>
<p>The company I work for relies on <code>Flask-Reuploaded</code> - so there is big motivation to keep it working.
Also, I love Python and open source, and I am super open for other contributors.</p>
<p>As a matter of fact, my dream would be a <code>Flask Umbrella</code> organization,
which the Flask plugin developers could join and share their workload more evenly.
See my proposal to the Pallets project here:
<a href="https://github.com/pallets/meta/issues/28">https://github.com/pallets/meta/issues/28</a></p>
<p>This all said...
I am super thankful to Max and all the other contributors to this and other open source packages.
I respect the decision not to release a package.
The beauty of open source is <strong>choice</strong>.
And now there is a choice when you want a working <a href="https://pypi.org/project/Flask-Reuploaded/">PyPi package</a>.</p>
<p>Thanks!</p>
<h2>Update, 2020-06-28</h2>
<p>Exactly 20 minutes after I have posted a similar, but shorter and more specific answer to one of the
<a href="https://github.com/maxcountryman/flask-uploads/issues/33">"current release is broken"</a>
issues on <code>Flask-Uploads</code> bug tracker,
the maintainer of <code>Flask-Uploads</code> fired a series of actions:</p>
<ul>
<li><p>he <a href="https://github.com/maxcountryman/flask-uploads/issues/33#issuecomment-650776662">kindly answered</a> to this one month old issue for the first time</p>
</li>
<li><p>he then marked <a href="https://github.com/maxcountryman/flask-uploads/issues/33#issuecomment-650772815">my answer</a> as off-topic, so it is hidden</p>
</li>
<li><p>he started to answering / closing all open issues, dating back til 2016</p>
</li>
<li><p>he created a <a href="https://github.com/maxcountryman/flask-uploads/issues/39">new ticket</a> and asked for help to automate releases to PyPi</p>
</li>
</ul>
<p>Guess what? This is almost exactly the reaction I anticipated.</p>
<p>One fork, probably four hours of work, which I enjoyed a lot,
and a very good looking solution for all users of either <code>Flask-Uploads</code> or <code>Flask-Reuploaded</code> is within reach.</p>
<h3>Concerning the call for help with the automated releases...</h3>
<p>I truly hope this will work out, and the many users of <code>Flask-Uploads</code>,
which had problems for months,
and probably never get to know <code>Flask-Reuploaded</code>,
get a working app again.</p>
<p>And Max, if you happen to read my blog any time...</p>
<p><strong>"If someone is so motivated..."</strong>
I was. I am no longer.
I have a different mental model of how open source works.</p>
<p><strong>"This will allow the maintainers (including myself) to easily create releases without having to setup the local tooling to do so (truly a pain and not something I personally have the time for at the moment)."</strong></p>
<p>There is an excellent blog post out there on how to do releases to PyPi, by Hynek Schlawack: <a href="https://hynek.me/articles/sharing-your-labor-of-love-pypi-quick-and-dirty/">Sharing Your Labor of Love: PyPI Quick and Dirty</a></p>
<p>Basically, you need a virtualenv and five minutes. That's it. I know it. <a href="https://github.com/jugmac00/flask-reuploaded/blob/master/PACKAGING.rst">I did it</a>. <a href="https://pypi.org/project/Flask-Reuploaded/">Twice</a>.</p>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/log-rotation-for-python-applications/">Log Rotation for Python Applications - Without killing them softly</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/@jugmac00">Jürgen Gmach</a>
    
    on 2020-04-08
  </p>
  <p>A couple of days after a successful deployment of my <a href="https://zope.readthedocs.io/en/latest/">Zope 4</a> application, I noticed something worrisome.</p>
<p>Zope gets killed every night, shortly after midnight.</p>
<p>I use <a href="http://supervisord.org/">Supervisor</a>, which monitors the process and restarts it, so that's not the problem.</p>
<p>But there are two problems:</p>
<ul>
<li>I did not trigger this on purpose.</li>
<li>The cache of my app is cold, that means that my colleagues get slow response times for the first queries in the morning.</li>
</ul>
<h2>What's wrong?</h2>
<p>Thanks to version controlled <a href="https://batou.readthedocs.io/en/latest/">configuration management</a> it was not hard to pick up a trail of the problem.</p>
<p>The commit which looked most promising was one about introducing proper log rotation with <code>Logrotate</code>.</p>
<p><code>Logrotate</code> manages automatic rotation and compression of your log files.</p>
<p>Log rotation was setup to send a signal to Zope to close and re-open the log file as following:</p>
<pre><code>/srv/app/deployment/work/zope/var/log/instance*.log  {

postrotate
kill -USR2 $(cat /srv/app/deployment/work/zope/var/instance/Z4.pid)
endscript
}
</code></pre>
<p><code>kill</code> sounds scary at first, but it isn't, or let's say, it shouldn't be.</p>
<p>It just sends a signal to a process - and <code>USR2</code> happens to be a signal for which your application can use a customized reaction, e.g. log close and re-open.</p>
<p>Looking at Zope's documentation, this is exactly how it should look like - and it definitely used to work this way back then with Zope 2. No mentions in the Zope documentation about a change.</p>
<pre><code>SIGUSR2
  close and re-open all Zope log files (z2.log, event log, detailed log.) The
  common idiom after rotating Zope log files is::

    kill -USR2 `cat $ZOPE_HOME/var/Z2.pid`
</code></pre>
<p>This excerpt was available under <a href="https://zope.readthedocs.io/en/latest/INSTALL.html">https://zope.readthedocs.io/en/latest/INSTALL.html</a> - meanwhile it was updated.</p>
<p>So, this looks like a Zope bug, eh?</p>
<p>Minimal setup to reproduce it... yep, Zope dies.</p>
<p>Some back and forth between Zope's and Waitress' (WSGI server) maintainers about who should fix this, and... there is nothing to fix.</p>
<p><strong>Zope decided to drop signal handling</strong> with the 2 to 4 update, and Waitress can't do it as it does not handle log files.</p>
<h2>Excuse me, sir. What is the real problem here?</h2>
<p>When <code>Logrotate</code> archives the current log file, and creates a new one, the current app's process keeps the handle to the original file, and keeps logging into it, although there is a new one.</p>
<p>Usually, you can restart your app or send a special signal, like USR2 to your app to fix this problem, but as outlined above, both options do not work out great with my use case.</p>
<h2>So, what to do?</h2>
<p>Turns out, there are many options!</p>
<ul>
<li>log to a supervising process</li>
<li>use <code>Logrotate</code>'s <a href="https://jlk.fjfi.cvut.cz/arch/manpages/man/logrotate.8#Files_and_Folders"><code>copytruncate</code></a> directive </li>
<li>use Python's <a href="https://docs.python.org/3/library/logging.handlers.html#watchedfilehandler"><code>WatchedFileHandler</code></a></li>
</ul>
<p>Having used Python for more than a decade, I still get surprised by gems in the standard library I never heard of before. Like the <code>WatchedFileHandler</code>.</p>
<p>While all three options are valid, the <code>WatchedFileHAndler</code> just does what is needed here. Watch the file for a change, then close the old file stream and open a new one.</p>
<p>The final "configuration" of <code>Logrotate</code> is this simple:</p>
<pre><code>/srv/app/deployment/work/zope/var/log/*.log  {

}
</code></pre>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/isort-and-pre-commit-a-friendship-with-obstacles/">isort and pre-commit - a friendship with obstacles</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/jugmac00">Jürgen Gmach</a>
    
    on 2020-02-23
  </p>
  <blockquote><p><strong><em>NOTE:</em></strong> 
This post is not intended to be an exhaustive introduction to <code>pre-commit</code> and its hooks. Please visit <a href="https://pre-commit.com/">pre-commit.com</a> for a complete documentation.</p>
</blockquote>
<p>In a nutshell...</p>
<h2>pre-commit</h2>
<p>From its <a href="https://pre-commit.com/">website</a>:</p>
<blockquote><p>A framework for managing and maintaining multi-language pre-commit hooks.</p>
</blockquote>
<p>Very simplified this means, whenever you try to commit changes in your project (e.g. entering <code>git commit</code>), <code>pre-commit</code> runs all configured tools (e.g. linter, formatter, ...), and only if they run successfully, your commit will be executed - otherwise your commit will fail.</p>
<p>This is really great, as you will never ever forget to run your linter or other tools.</p>
<h2>isort</h2>
<p>One of those tools, which pre-commit can execute for you, is <code>isort</code> - short for "sort imports".</p>
<p>As the name suggests, this little helper sorts your import statements, both alphabetical and also PEP 8 compliant, means e.g. standard library imports are separated from the ones of third party tools. And I like this a lot!</p>
<p>A sample configuration for <code>pre-commit</code> to use <code>isort</code> could look like this - by the way, this is YAML:</p>
<pre><code>-   repo: https://github.com/timothycrosley/isort
    rev: 4.3.21
    hooks:
    -   id: isort
</code></pre>
<p>Also, you can customize <code>isort</code> to our liking, ie. every import on one line. This is just one of many configuration options.</p>
<p>And with the configuration options there comes the first problem.</p>
<h2>don't touch my migrations</h2>
<p>Whenever you run an application with a relational database, you probably also need to keep track of <code>migrations</code>, which usually consists of files with the diffs between two database schemes.</p>
<p>For my Flask app, those are stored in a subfolder called <code>migrations</code>.</p>
<p>No problem at all! Let's use <code>isort's</code> <code>skip</code> / <code>skip-glob</code> option (see  <code>isort's</code> <a href="https://github.com/timothycrosley/isort/wiki/isort-Settings">wiki</a>.</p>
<p>Looks easy enough.</p>
<p>After some <a href="https://github.com/timothycrosley/isort/issues/282">googling</a> - my first try would be something like this:</p>
<pre><code>[isort]
skip = migrations
</code></pre>
<p>Does not work. Hm, maybe I need to use globbing (wildcards)?</p>
<blockquote><p><strong><em>NOTE:</em></strong> 
I put <code>isort</code>'s configuration into my <code>tox.ini</code> file - you can certainly also use a dedicated <code>.isort.cfg</code> file. You'd have to replace the section <code>isort</code> with <code>settings</code> then.</p>
</blockquote>
<p>After some more googling I came up with this:</p>
<pre><code>[isort]
skip_glob = */migrations/*.py
</code></pre>
<p>Guess what? This also does not work. All my migration files still get changed by <code>isort</code>.</p>
<p>After some more investigation, I found  <a href="https://github.com/timothycrosley/isort/issues/885">https://github.com/timothycrosley/isort/issues/885</a>:</p>
<p>There is a new "never skip when passed a filename" behavior - which is... new. So, even if you put a file or a pattern into a <code>skip</code> option, it does not get skipped when passed to <code>isort</code> directly. And this is what I assume <code>pre-commit</code> is doing.</p>
<p>Ok, in the same issue a workaround was mentioned:
Use <code>--filter-files</code> on the command line, which I do not use, as I use <code>pre-commit</code>, but fortunately you can add it to your <code>pre-commit</code> hook configuration:</p>
<pre><code>  - repo: https://github.com/timothycrosley/isort
    rev: 4.3.21
    hooks:
    - id: isort
      args: [--filter-files]
</code></pre>
<p>It works!</p>
<blockquote><p><strong><em>NOTE:</em></strong> 
As an <a href="https://www.gitmemory.com/issue/pre-commit/mirrors-isort/9/511434587">alternative</a>, you could also add an <code>exclude: migrations/</code> statement in your pre-commit-config.yaml.</p>
</blockquote>
<p>Let me rather say... it worked, until I updated from <code>4.3.21</code> to <code>4.3.21-2</code> - there are no changelog entries available for this update, but there were tons of changes, including different behavior which files should be scanned.</p>
<p>With this update, all files gets processed by <code>isort</code>, including <code>.po</code>, <code>.rst</code>, <code>.json</code> and many more.</p>
<p>Ok, what can we do about it?</p>
<p>First, file an issue (<a href="https://github.com/timothycrosley/isort/issues/1154">https://github.com/timothycrosley/isort/issues/1154</a>).</p>
<p>Reading the excellent <code>pre-commit</code> documentation, it seems there are several options, but <a href="https://pre-commit.com/#creating-new-hooks"><code>filter by files</code></a> looks very promising.</p>
<p>The <code>files</code> statement supports regular expressions, so the new hook looks like this:</p>
<pre><code>  - repo: https://github.com/timothycrosley/isort
    rev: 4.3.21-2
    hooks:
    - id: isort
      args: [--filter-files]
      files: \.py$
</code></pre>
<p>And here we go... finally works as intended.</p>
<h2>post scriptum</h2>
<p>How does <code>isort</code> know how to sort the imports?</p>
<p>I don' t know, but it looks like Anthony Sottile knows a thing or two about this, and so he even wrote a tool which pre-polulates <code>isort's</code> <code>known_third_party</code> configuration, and thus makes <code>isort</code> even work better.</p>
<p>For more information and the <code>pre-commit</code> configuration please refer to <a href="https://github.com/asottile/seed-isort-config">https://github.com/asottile/seed-isort-config</a>.</p>
<h2>Update</h2>
<p>I could track down the the faulty behavior (<code>isort</code> also touches files which are not Python files) to a regression/packaging bug - <code>.pre-commit-hook.yaml</code> is broken for 4.3.21-2 - see the issue at <code>isort</code>'s <a href="https://github.com/timothycrosley/isort/issues/1154#issuecomment-587517806">bug tracker</a>.</p>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/three-ways-to-get-into-trouble-or-welcome-back-pagetemplateengine/">Three ways to get into trouble or welcome back PageTemplateEngine</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/jugmac00">Jürgen Gmach</a>
    
    on 2019-11-26
  </p>
  <p>The web application server <a href="https://en.wikipedia.org/wiki/Zope">Zope</a> has a very long history which dates back to the late '90s.</p>
<p>Quoting <a href="https://twitter.com/faassen/status/1197219574711803905">Martijn Faassen</a>:</p>
<blockquote><p>Zope must be one of the oldest Python codebases in the world that is still used outside the standard library.</p>
</blockquote>
<p>During its many years of existence the way a view gets rendered has changed.</p>
<p>Basically there are two supported template mechanisms:</p>
<ul>
<li>Document Template Markup Language (DTML)</li>
<li>Zope Page Templates (ZPT)</li>
</ul>
<p>DTML is pretty much outdated for more than a decade, but still in use for the Zope Management Interface.</p>
<p>ZPTs are basically XML/HTML pages in which special markup is embedded (<a href="https://en.wikipedia.org/wiki/Template_Attribute_Language">TAL</a>), which gets processed server side.</p>
<p>The processing is done by a template engine - this used to be the PageTemplateEngine.</p>
<p>With the release of Zope 4 this engine has been superseded by the <a href="https://github.com/malthe/chameleon">Chameleon</a> template engine, which is now activated per default.</p>
<p>While Chameleon offers more flexibility and better performance, there may be reasons(TM) for using the old template engine.</p>
<h2>word of caution</h2>
<p>As of using Zope 4.1, the old PageTemplateEngine currently works, but is deprecated and subject to be <a href="https://github.com/zopefoundation/Zope/issues/104">removed anytime</a>.</p>
<h2>activate pageTemplateEngine</h2>
<p>True to the Python motto <strong>"There should be one—and preferably only one—obvious way to do it."</strong> there is no obvious,  but three rather obscure ways to get back the old engine - at least for the ZCML apprentice. <a href="https://docs.plone.org/develop/addons/components/zcml.html">ZCML</a> stands for Zope Configuration Mark-up Language.</p>
<p>ZCML was introduced with Zope 3, and is used to wire together different parts of your application.</p>
<h3>one</h3>
<p>Go to <code>src/Products/PageTemplates/configure.zcml</code> and comment out the configuration.</p>
<p>This can only be a temporary solution, as you should not modify an upstream package, e.g. Zope.</p>
<h3>two</h3>
<p>Make use of <a href="https://pypi.org/project/z3c.unconfigure/">z3c.unconfigure</a> and unconfigure the registration.</p>
<h3>three</h3>
<p>Create an <code>overrides.zcml</code> with the following content:</p>
<pre><code>&lt;configure xmlns="http://namespaces.zope.org/zope"
           xmlns:zcml="http://namespaces.zope.org/zcml"&gt;

  &lt;!-- This registration disables Chameleon templates on Zope 4. --&gt;
  &lt;utility
    zcml:condition="installed chameleon"
    component="zope.pagetemplate.pagetemplate.PageTemplateEngine" /&gt;

&lt;/configure&gt;
</code></pre>

  </div>

  
    
  <div class="blog-post">
  
    <h1><a href="../blog/am-i-famous/">Am I famous?</a></h2>
  
  <p class="meta">
    written by
    
      <a href="https://twitter.com/jugmac00">Jürgen Gmach</a>
    
    on 2019-05-29
  </p>
  <p>A couple of months ago, Brett Cannon, one of the better known Python core developers, announced on <a href="https://twitter.com/brettsky/status/1096578335428112384">Twitter</a> that he contributed to over 100 open source projects.</p>
<h2>first reaction</h2>
<p>Woohah! Congratulations!</p>
<h2>second reaction</h2>
<p>How did he know?</p>
<blockquote><p>Everytime I get a PR merged I record the repo's URL for a tool I created to analyze my contributions to OSS.</p>
</blockquote>
<p>Ah... k. I did not do that.</p>
<h2>third reaction</h2>
<p>To how many open source projects did I contribute? Well, I only started contributing recently, like one year ago or so... and as I said, I did not take any notes... but <strong>luckily</strong> nowadays like most open source development happens on Github. As far as I remember I only contributed to a couple projects which are not present on Github, and that was for <a href="https://bitbucket.org/flyingcircus/batou">batou</a> and <a href="http://trac.roundcube.net/">Roundcube</a>.</p>
<p>So, if only Github provided some API to query the data it stored about me... well, it does.</p>
<h2>say hello to graphql</h2>
<p><strong>GraphQL</strong> is a query language for web APIs. It was developed by Facebook, and according to rumors it will supersede REST in the near future.</p>
<p>Github kindly not only offers an API, but also an <a href="https://developer.github.com/v4/explorer/">in-browser IDE</a> (based on <a href="https://github.com/graphql/graphiql">GraphiQL</a>) to explore the data.</p>
<h2>say hello to graphiql</h2>
<p>When you first hit Github's instance of GraphiQL ( <a href="https://developer.github.com/v4/explorer/">https://developer.github.com/v4/explorer/</a> ), you will see something like this:</p>
<p><img src="../blog/am-i-famous/github-graphiql-start.png" alt="Alt-Text"></p>
<p>So, obviously, first you have to login with your Github credentials (green "Sign in with Github" button in the top right).</p>
<h2>first encounter</h2>
<p>When I first saw this page, I played around a bit and left - as I did not get what I wanted. Luckily, at last weekend's <strong>PyConWeb19</strong>, Arthur Bayr did a workshop on <a href="https://pyconweb.com/talks/25-05-2019/introduction-to-graphql-and-graphene">GraphQL and Graphene</a> - thanks a ton!</p>
<p>Now I am ready to explore my data!</p>
<h2>overview</h2>
<p>On the top left, there is room to enter the query.</p>
<p>On the right, the result will be shown.</p>
<p>On the far right, there is the small, but super helpful <strong>Docs</strong> button.</p>
<p>On the bottom left is something I did not use yet.</p>
<h2>iteration one</h2>
<p>After you have logged in, leave the query as is...</p>
<pre><code>query { 
  viewer { 
    login
  }
}
</code></pre>
<p>...  and just hit the play button above the "query field".</p>
<p>You should get a result similar to mine - but with your username</p>
<pre><code>{
  "data": {
    "viewer": {
      "login": "jugmac00"
    }
  }
}
</code></pre>
<h3>explanation</h3>
<ul>
<li><strong>query</strong> outside the curly braces is just a name</li>
<li><strong>viewer</strong> is a data type, and it happens to be the currently authenticated in user</li>
<li><strong>login</strong> is a subfield of <strong>viewer</strong></li>
</ul>
<p>How do I know this?</p>
<p>On the far right, there is the <strong>Docs</strong> button. Small button, but lots and lots of information! Actually, you can explore the complete API when you open the docs and follow the links.</p>
<h2>iteration two</h2>
<p>Either by reading the docs or by hitting <strong>CTRL+SPACE</strong> which triggers autocompletion when you are in the query box, you will eventually come across a subfield with name <strong>repositoriesContributedTo</strong> - that sounds fine!</p>
<blockquote><p><strong><em>NOTE:</em></strong><br>
You cannot query arbitrary data - all fields, subfields, parameters... have to be defined by the API provider.</p>
</blockquote>
<p>When you just enter the following...</p>
<pre><code>query { 
  viewer {
    repositoriesContributedTo
  } 
}
</code></pre>
<p>... right below <strong>repostoriesContributetTo</strong> there will be a red squiggly line. When hover over the word, you can read "Field .. must have a selection of subfields".</p>
<p>Whatever! The cool thing.. if you hit the <strong>play</strong> button anyway, the IDE autocompletes your query to...</p>
<pre><code>query { 
  viewer {
    repositoriesContributedTo {
      edges {
        node {
          id
        }
      }
    }
  } 
}
</code></pre>
<p>The result is... hm... an error message: "You must provide a <code>first</code> or <code>last</code> value to properly paginate the <code>repositoriesContributedTo</code> connection."</p>
<p>Ok, let's do this.</p>
<h2>iteration three</h2>
<p>Generally speaking, it is a very good idea to force pagination on all APIs, which return lists - another thing I learned at PyConWeb19 - no slides, but there is a video from another conference: <a href="https://www.youtube.com/watch?v=WXSfE2rE3bM">Tech bankruptcy: Looking back on a decade of bad decision making</a></p>
<p>The mentioned <strong>value</strong> is actually a parameter, and parameters are put into parenthesis behind a (sub)fieldname, just like...</p>
<pre><code>query { 
  viewer {
    repositoriesContributedTo(first: 100) {
      edges {
        node {
          id
        }
      }
    }
  } 
}
</code></pre>
<p>If you only type <strong>first</strong>, you get a friendly reminder to provide a number, which must not be greater than 100.</p>
<p>The result...</p>
<pre><code>{
  "data": {
    "viewer": {
      "repositoriesContributedTo": {
        "edges": [
          {
            "node": {
              "id": "MDEwOlJlcG9zaXRvcnk2OTI2NTQ="
            }
          },
...
</code></pre>
<p>... does not look to bad, but not very human readable.</p>
<h2>iteration four</h2>
<p>If you replace <strong>id</strong> with <strong>nameWithOwner</strong> (via API exploration STRG+SPACE or from the docs), you'll get much better data:</p>
<pre><code>query { 
  viewer {
    repositoriesContributedTo(first: 100) {
      edges {
        node {
          nameWithOwner
        }
      }
    }
  } 
}
</code></pre>
<p>The result...</p>
<pre><code>{
  "data": {
    "viewer": {
      "repositoriesContributedTo": {
        "edges": [
          {
            "node": {
              "nameWithOwner": "python-babel/flask-babel"
            }
          },
          {
            "node": {
              "nameWithOwner": "malthe/chameleon"
            }
          },
...
</code></pre>
<p>But we want the total number of contributions.</p>
<h2>iteration five</h2>
<p>As I learned at the workshop, either the server or the client has to implement some count or sum functions, as you can only query what is offered (or process it client side).</p>
<p>So, let's have another look, what <strong>repositoriesContributedTo</strong> has to offer...</p>
<p>If you click on <strong>repositoriesContributedTo</strong> and then on <strong>RepositoryConnection!</strong> in the <strong>Docs</strong>, you'll see <strong>totalCount</strong> -  nice! And also, you'll see <strong>nodes</strong> - which can simplify the "first get all edges and then the corresponding nodes" syntax.</p>
<pre><code>query { 
  viewer {
    repositoriesContributedTo(first: 100) {
        totalCount
        nodes {
          nameWithOwner
      }
    }
  } 
}
</code></pre>
<p>The result...</p>
<pre><code>{
  "data": {
    "viewer": {
      "repositoriesContributedTo": {
        "totalCount": 66,
        "nodes": [
          {
            "nameWithOwner": "python-babel/flask-babel"
          },
          {
            "nameWithOwner": "malthe/chameleon"
          },
...
</code></pre>
<p>Very nice.. except... also proprietary (private) repositories are listed...</p>
<h2>iteration six</h2>
<p>Visiting the docs again, <strong>repositoriesContributedTo</strong> offers a <strong>privacy</strong> parameter.</p>
<pre><code>query { 
  viewer {
    repositoriesContributedTo(first: 100, privacy: PUBLIC) {
        totalCount
        nodes {
          nameWithOwner
      }
    }
  } 
}
</code></pre>
<p>The final result...</p>
<pre><code>{
  "data": {
    "viewer": {
      "repositoriesContributedTo": {
        "totalCount": 54,
        "nodes": [
          {
            "nameWithOwner": "python-babel/flask-babel"
          },
          {
            "nameWithOwner": "malthe/chameleon"
          },
...
</code></pre>
<h2>what's left</h2>
<p>First, once again, thank you very much Arthur for teaching me the basics of <strong>GraphQL</strong>!</p>
<p>Now it is up to the reader to explore the API further... oh wait.. what is the <strong>includeUserRepositories</strong> parameter doing...</p>
<p>Damn! I missed to include my very own projects! :-)</p>
<h2>notes</h2>
<p>I presented this topic as a lightning talk at <a href="https://www.meetup.com/de-DE/Mobile-Stammtisch-GDG-Regensburg/events/266429981/">Mobile Stammtisch/GDG Regensburg</a> on 12. December 2019.</p>
<h2>updates</h2>
<p>2019-12-28</p>
<ul>
<li>add notes about lightning talk</li>
</ul>

  </div>

  

  
  <div class="pagination">
    
      <span class="disabled">&laquo; Previous</span>
    
    | 1 |
    
      <a href="../blog/page/2/">Next &raquo;</a>
    
  </div>


  </div>
  <footer>
    &copy; Copyright 2018 - 2021 by Jürgen Gmach.
  </footer>
</body>
